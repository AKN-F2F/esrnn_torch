{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils_data import M4TS\n",
    "from src.utils_data import get_m4_all_series\n",
    "\n",
    "from src.utils_config import ModelConfig\n",
    "from src.utils_visualization import plot_prediction\n",
    "\n",
    "from src.utils_train import SmylLoss\n",
    "# from src.utils_models import VanillaLSTM\n",
    "# from src.utils_models import ES\n",
    "from src.utils_models import ES, RNN, ESRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelConfig(config_file='configs/config_m4quarterly.yaml',\n",
    "                 root_dir='./results/')\n",
    "\n",
    "all_series = get_m4_all_series(mc=mc, data='train')\n",
    "# train(mc, all_series)\n",
    "\n",
    "# model = ESRNN(mc)\n",
    "# print(\"\\n Model parameters: \\n\", model.rnn.parameters, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mc, all_series):\n",
    "    print(10*'='+' Training {} '.format(mc.dataset_name) + 10*'=')\n",
    "    #torch.set_default_tensor_type(torch.float32)\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    # Random Seeds\n",
    "    torch.manual_seed(mc.copy)\n",
    "    np.random.seed(mc.copy)\n",
    "\n",
    "    # Model\n",
    "    esrnn = ESRNN(mc)\n",
    "\n",
    "    # Optimizers\n",
    "    es_optimizer = optim.Adam(params=esrnn.es.parameters(),\n",
    "                              lr=mc.learning_rate*mc.per_series_lr_multip, \n",
    "                              betas=(0.9, 0.999), eps=mc.gradient_eps)\n",
    "\n",
    "    rnn_optimizer = optim.Adam(params=esrnn.rnn.parameters(),\n",
    "                         lr=mc.learning_rate,\n",
    "                         betas=(0.9, 0.999), eps=mc.gradient_eps)\n",
    "    \n",
    "    # Loss Functions\n",
    "    smyl_loss = SmylLoss(tau=mc.tau,\n",
    "                         level_variability_penalty=mc.level_variability_penalty)\n",
    "\n",
    "    # training code\n",
    "    for epoch in range(mc.max_epochs):\n",
    "        start = time.time()\n",
    "        forecast_losses = []\n",
    "        lev_variability_losses = []\n",
    "        state_losses = []\n",
    "        \n",
    "        for j in range(len(all_series)):\n",
    "            es_optimizer.zero_grad()\n",
    "            rnn_optimizer.zero_grad()\n",
    "\n",
    "            ts_object = all_series[j]\n",
    "            windows_y, windows_y_hat, levels = esrnn(ts_object)\n",
    "            \n",
    "            loss = smyl_loss(windows_y, windows_y_hat, levels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad(esrnn.rnn.parameters,\n",
    "                                     max_norm=mc.gradient_clipping_threshold)\n",
    "            torch.nn.utils.clip_grad(esrnn.es.parameters,\n",
    "                                     max_norm=mc.gradient_clipping_threshold)\n",
    "            rnn_optimizer.step()\n",
    "            es_optimizer.step()\n",
    "        \n",
    "        if epoch >= (mc.max_epochs-mc.averaging_level):\n",
    "            copy = epoch+mc.averaging_level-mc.max_epochs\n",
    "            esrnn.save(copy=copy)\n",
    "\n",
    "        print(\"========= Epoch {} finished =========\".format(epoch))\n",
    "        print(\"Training time: {}\".format(time.time()-start))\n",
    "        print(\"Forecast loss: {}\".format(np.mean(forecloss_ex.npvalue())))\n",
    "\n",
    "    print('Train finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Training m4quarterly ==========\n",
      "input_data.dtype torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1565272679438/work/torch/csrc/autograd/python_anomaly_mode.cpp:57: UserWarning: Traceback of forward call that caused the error:\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/gen.py\", line 714, in __init__\n",
      "    self.run()\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3242, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-87863a49d1aa>\", line 1, in <module>\n",
      "    train(mc, all_series)\n",
      "  File \"<ipython-input-4-5cc609f1f426>\", line 38, in train\n",
      "    windows_y, windows_y_hat, levels = esrnn(ts_object)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/kin_gutierrez/Desktop/esrnn_torch/src/utils_models.py\", line 142, in forward\n",
      "    levels, seasonalities = self.es(ts_object)\n",
      "  File \"/Users/kin_gutierrez/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/kin_gutierrez/Desktop/esrnn_torch/src/utils_models.py\", line 53, in forward\n",
      "    seasonalities[:, [t+self.seasonality]] = seas_sms * (y[:, [t]] / levels[:, [t]]) + (1-seas_sms) * seasonalities[:, [t]]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 29]], which is output 0 of SliceBackward, is at version 25; expected version 24 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-87863a49d1aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-5cc609f1f426>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(mc, all_series)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmyl_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindows_y_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             torch.nn.utils.clip_grad(esrnn.rnn.parameters,\n\u001b[1;32m     43\u001b[0m                                      max_norm=mc.gradient_clipping_threshold)\n",
      "\u001b[0;32m~/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/esrnn_torch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 29]], which is output 0 of SliceBackward, is at version 25; expected version 24 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "train(mc, all_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(mc)\n",
    "print(\"\\n Model parameters: \\n\", model.rnn.parameters, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.float32(ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esrnn_torch",
   "language": "python",
   "name": "esrnn_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
