{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.M4_data import prepare_M4_data\n",
    "from src.M4_experiment import plot_model_prediction, evaluate_model_prediction\n",
    "from src.ESRNN import ESRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df, y_train_df, X_test_df, y_test_df = prepare_M4_data('Yearly', num_obs=10) #, num_obs=5\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "## Weekly\n",
    "# esrnn = ESRNN(max_epochs=4, batch_size=4, dilations=[[1, 4], [52]], rnn_weight_decay=0.5, freq_of_test=1)\n",
    "\n",
    "## Quarterly\n",
    "# esrnn = ESRNN(max_epochs=1, batch_size=3, rnn_weight_decay=0.5, freq_of_test=1)\n",
    "\n",
    "## Daily\n",
    "# esrnn = ESRNN(max_epochs=2, batch_size=16, learning_rate=3e-4, per_series_lr_multip=1.5,\n",
    "#               gradient_eps=1e-6, level_variability_penalty=100,\n",
    "#               dilations=[[1,7],[28]], add_nl_layer=True,\n",
    "#               seasonality=[7], input_size=7, output_size=14)\n",
    "\n",
    "# # Debugging Quarterly\n",
    "# with torch.autograd.detect_anomaly():\n",
    "#     esrnn = ESRNN(max_epochs=1, max_periods=1, batch_size=3, state_hsize=4,\n",
    "#                   seasonality=[1], input_size=3, output_size=8, dilations=[[1, 2]],\n",
    "#                   rnn_weight_decay=0.0, freq_of_test=1, random_seed=1, cell_type='LSTM')\n",
    "#     esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)\n",
    "\n",
    "# # Proof of Concept Quarterly\n",
    "# esrnn = ESRNN(max_epochs=2, max_periods=20, batch_size=1, state_hsize=40,\n",
    "#               learning_rate = 0.001, per_series_lr_multip=1.5,\n",
    "#               seasonality=[], input_size=4, output_size=8, dilations=[[1, 2], [4, 8]],\n",
    "#               rnn_weight_decay=0.0, freq_of_test=1, random_seed=1, cell_type='ResLSTM')\n",
    "# esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)\n",
    "\n",
    "# # Debugging Quarterly\n",
    "# print(\"\\n\\n\")\n",
    "# with torch.autograd.detect_anomaly():\n",
    "#     esrnn = ESRNN(max_epochs=1, max_periods=1, batch_size=10, state_hsize=4, per_series_lr_multip=1.5,\n",
    "#                   seasonality=[1, 2], input_size=3, output_size=8, dilations=[[1, 2]],\n",
    "#                   rnn_weight_decay=0.0, freq_of_test=1, random_seed=1, cell_type='LSTM',\n",
    "#                   level_variability_penalty=0)\n",
    "#     esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)\n",
    "    \n",
    "# Debugging Yearly\n",
    "with torch.autograd.detect_anomaly():\n",
    "    esrnn = ESRNN(max_epochs=1, max_periods=1, batch_size=5, state_hsize=4,\n",
    "                  seasonality=[], input_size=3, output_size=6, dilations=[[1, 2]],\n",
    "                  rnn_weight_decay=1.0, freq_of_test=1, random_seed=1, cell_type='ResLSTM')\n",
    "    esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)\n",
    "\n",
    "## Debugging Hourly\n",
    "# with torch.autograd.detect_anomaly():\n",
    "#     esrnn = ESRNN(max_epochs=4, max_periods=1, batch_size=3, state_hsize=4,\n",
    "#                   seasonality=[24, 168], input_size=3, output_size=48, dilations=[[1, 2]],\n",
    "#                   rnn_weight_decay=1.0, freq_of_test=1, random_seed=1, cell_type='LSTM')\n",
    "#     esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)\n",
    "\n",
    "# # Debugging Weekly\n",
    "# with torch.autograd.detect_anomaly():\n",
    "#     esrnn = ESRNN(max_epochs=1, max_periods=1, batch_size=3, state_hsize=4,\n",
    "#                   seasonality=[52], input_size=10, output_size=13, dilations=[[1, 52]],\n",
    "#                   rnn_weight_decay=1.0, freq_of_test=1, random_seed=1, cell_type='LSTM')\n",
    "#     esrnn.fit(X_train_df, y_train_df, X_test_df, y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = esrnn.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_prediction(y_train_df, X_test_df, y_test_df, model=esrnn, u_id='Q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrnn.evaluate_model_prediction(y_train_df, X_test_df, y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M4 eval\n",
    "#(0.778*(23.0/100) + 0.847*(24.0/100) + 0.836*(48.0/100) + 0.920*(5.0/100))\n",
    "#(13.176*() + 9.679*() + 12.126*())\n",
    "#(14.42*(23.0/(23+24+48)) + 10.09*(24.0/(23+24+48)) + 10.81*(48.0/(23+24+48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hyperpar_tunning_m4 import parse_grid_search\n",
    "from src.utils_visualization import plot_grid_cat_distributions\n",
    "\n",
    "gs_df = parse_grid_search('Daily')\n",
    "# plot_cat_distributions(df=gs_df, cat='learning_rate', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='add_nl_layer', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='rnn_weight_decay', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='per_series_lr_multip', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='batch_size', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='training_percentile', var='min_owa')\n",
    "# plot_cat_distributions(df=gs_df, cat='dilations', var='min_owa')\n",
    "\n",
    "gs_df['early_stopping'] = gs_df.min_epoch < gs_df.max_epochs\n",
    "#gs_df = gs_df[gs_df.min_owa<1.5]\n",
    "plot_grid_cat_distributions(gs_df, var = 'min_owa',\n",
    "                            cats=['learning_rate', 'per_series_lr_multip', 'per_series_lr_multip',\n",
    "                                  'batch_size', 'max_epochs', 'max_periods', 'dilations',\n",
    "                                  'rnn_weight_decay'])\n",
    "#gs_df.learning_rate.min()\n",
    "# fgs_df = gs_df[gs_df.rnn_weight_decay==0.0]\n",
    "fgs_df = gs_df\n",
    "fgs_df.groupby('rnn_weight_decay')['min_owa'].mean()\n",
    "# 'batch_size' : [8, 16]\n",
    "# 'learning_rate': [3e-4, 5e-4, 1.0e-3, 1.5e-3]\n",
    "# 'per_series_lr_multip': [1.5, 2.0, 3.0]\n",
    "# 'training_percentile' : [45, 50]\n",
    "# 'max_periods': [10, 15]\n",
    "# 'cell_type': ['LSTM']\n",
    "# 'dilations' : [[[1, 7, 28]]]\n",
    "# 'ensemble': [True]\n",
    "# 'add_nl_layer' : [False],\n",
    "# 'random_seed': [1, 2, 117, 120652, 117982, 1210357]\n",
    "# gs_df.min_owa.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "DAILY = {'model_type': ['esrnn'],\n",
    "         'dataset': ['Daily'],\n",
    "         'max_epochs' : [100],\n",
    "         'batch_size' : [8, 16],\n",
    "         'freq_of_test': [4],\n",
    "         'learning_rate': [3e-4, 5e-4, 1.0e-3, 1.5e-3],\n",
    "         'lr_scheduler_step_size' : [9],\n",
    "         'lr_decay' : [0.333],\n",
    "         'per_series_lr_multip': [1.5, 2.0, 3.0],\n",
    "         'gradient_clipping_threshold' : [50],\n",
    "         'rnn_weight_decay' : [0.05, 0.01],\n",
    "         'noise_std' : [1e-3],\n",
    "         'level_variability_penalty' : [100],\n",
    "         'percentile' : [50],\n",
    "         'training_percentile' : [45],\n",
    "         'max_periods': [10, 15],\n",
    "         'cell_type': ['LSTM', 'ResLSTM'],\n",
    "         'state_hsize' : [40],\n",
    "         'dilations' : [[[1, 7, 28]]],\n",
    "         'add_nl_layer' : [True],\n",
    "         'seasonality' : [[7]],\n",
    "         'input_size' : [7],\n",
    "         'output_size' : [14],\n",
    "         'random_seed': [1, 2, 117, 120652, 117982, 1210357],\n",
    "         'device' : ['cuda']}\n",
    "\n",
    "model_specs = DAILY\n",
    "\n",
    "specs_list = list(itertools.product(*list(model_specs.values())))\n",
    "model_specs_df = pd.DataFrame(specs_list,\n",
    "                        columns=list(model_specs.keys()))\n",
    "\n",
    "len(model_specs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver2 = ver[ver.y_hat.isnull()]\n",
    "ver2 = ver[y_test_df.unique_id=='W1']\n",
    "ver3 = y_test_df[y_test_df.unique_id=='W2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = gs_df[gs_df.min_owa == gs_df.min_owa.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size = 8\n",
    "input_size = 7\n",
    "hidden_size = 2\n",
    "attention_hsize = 3\n",
    "\n",
    "inputs_list = [np.ones((batch_size, input_size))*1.0, \n",
    "               np.ones((batch_size, input_size))*2.0, \n",
    "               np.ones((batch_size, input_size))*3.0]\n",
    "inputs = torch.tensor(inputs_list, dtype=torch.float)\n",
    "\n",
    "hx = torch.ones(batch_size, hidden_size) * 10\n",
    "cx = torch.ones(batch_size, hidden_size) * 20\n",
    "\n",
    "attn_layer = nn.Sequential(nn.Linear(2 * hidden_size + input_size, attention_hsize),\n",
    "                           nn.Tanh(),\n",
    "                           nn.Linear(attention_hsize, 1))\n",
    "\n",
    "hx_rep = hx.repeat(len(inputs), 1, 1)\n",
    "cx_rep = cx.repeat(len(inputs), 1, 1)\n",
    "x = torch.cat((inputs, hx_rep, cx_rep), dim=-1)\n",
    "beta = attn_layer(x)\n",
    "beta = nn.Softmax(dim=0)(beta)\n",
    "context = torch.bmm(beta.permute(1, 2, 0), \n",
    "                    inputs.permute(1, 0, 2)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esrnn_torch",
   "language": "python",
   "name": "esrnn_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
